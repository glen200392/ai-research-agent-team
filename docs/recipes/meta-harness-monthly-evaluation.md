# Meta Harness â€” Monthly Quality Evaluation & Evolution Report

**Schedule:** 1st of every month, 09:00 CST (cron: `0 9 1 * *`)  
**Layer:** 4 â€” Meta Harness (Vertical Integration & Coordination)  
**Purpose:** Self-evaluation of all three teams + HITL upgrade approval  
**Output:** Cross-team insight report â†’ saved to `docs/meta-harness/` + Email to Glennn for HITL

---

## Pipeline Steps

### Step 1 â€” Last Month AI Research Baseline (read-only)
- **Action:** `web-search`
- **Query:** `AI agent LLM major breakthroughs research milestones last month $30d_ago|date to $today|date`
- **Citations:** true
- **Purpose:** Establishes ground truth for evaluating Team A's coverage accuracy

### Step 2 â€” AI Education Best Practices Baseline (read-only)
- **Action:** `web-search`
- **Query:** `AI education best practices explainable AI knowledge transfer pedagogy 2026`
- **Citations:** true
- **Purpose:** Establishes benchmark for evaluating Team C's pedagogy quality

### Step 3 â€” Team A Quality Review (agent: ai-research-advisor)
Evaluates Team A (Current Intelligence) against Step 1 baseline.

**Output JSON:**
```json
{
  "team": "Team A â€” Current Intelligence",
  "evaluation_month": "$today|date",
  "scores": {
    "coverage_breadth": {"score": 0-100, "comment": "which domains covered, which missed"},
    "technical_accuracy": {"score": 0-100, "comment": "accuracy of technical descriptions"},
    "insight_depth": {"score": 0-100, "comment": "depth beyond news aggregation"},
    "actionability": {"score": 0-100, "comment": "how actionable the recommendations are"}
  },
  "overall_score": 0-100,
  "strengths": ["strength1", "strength2"],
  "improvement_areas": ["area1", "area2"],
  "upgrade_needed": true/false,
  "upgrade_suggestion": "if upgrade_needed, specific upgrade direction"
}
```

### Step 4 â€” Team B Quality Review (agent: ai-research-advisor)
Evaluates Team B (Evolution Chronicle) against Step 1 baseline.

**Output JSON:**
```json
{
  "team": "Team B â€” Evolution Chronicle",
  "evaluation_month": "$today|date",
  "scores": {
    "historical_depth": {"score": 0-100, "comment": "time depth and completeness of tracing"},
    "connection_accuracy": {"score": 0-100, "comment": "accuracy of tech evolution links"},
    "narrative_quality": {"score": 0-100, "comment": "how engaging the storytelling is"},
    "predictive_value": {"score": 0-100, "comment": "accuracy of future evolution predictions"}
  },
  "overall_score": 0-100,
  "strengths": ["strength1", "strength2"],
  "improvement_areas": ["area1", "area2"],
  "upgrade_needed": true/false,
  "upgrade_suggestion": "if upgrade_needed, specific upgrade direction"
}
```

### Step 5 â€” Team C Quality Review (agent: ai-research-advisor)
Evaluates Team C (Pedagogy Federation) against Step 2 baseline.

**Output JSON:**
```json
{
  "team": "Team C â€” Pedagogy Federation",
  "evaluation_month": "$today|date",
  "scores": {
    "level_appropriateness": {"score": 0-100, "comment": "how well 3 levels serve target audiences"},
    "conceptual_accuracy": {"score": 0-100, "comment": "accuracy of teaching content"},
    "pedagogy_quality": {"score": 0-100, "comment": "teaching design and knowledge transfer effectiveness"},
    "quiz_quality": {"score": 0-100, "comment": "quiz quality and discrimination power"}
  },
  "overall_score": 0-100,
  "strengths": ["strength1", "strength2"],
  "improvement_areas": ["area1", "area2"],
  "upgrade_needed": true/false,
  "upgrade_suggestion": "if upgrade_needed, specific upgrade direction"
}
```

### Step 6 â€” Meta Harness Integrated Analysis (agent: ai-research-advisor)
Synthesizes Steps 3-5 into the monthly system evolution report.

**Output format (Traditional Chinese Markdown):**
```markdown
# AI Research Federation â€” æœˆåº¦ Meta Harness è©•ä¼°å ±å‘Š
**è©•ä¼°æœˆä»½ï¼š** $today|date

## ä¸€ã€ä¸‰åœ˜éšŠç¶œåˆè©•åˆ†
| åœ˜éšŠ | ç¸½åˆ† | æœ€å¼·é … | æœ€å¼±é … |
|------|------|--------|--------|
| Team A | X/100 | ... | ... |
| Team B | X/100 | ... | ... |
| Team C | X/100 | ... | ... |

## äºŒã€æœ¬æœˆæœ€å¤§äº®é»ž
ï¼ˆtop 2-3 commendable performances across all teamsï¼‰

## ä¸‰ã€è·¨åœ˜éšŠå”åŒåˆ†æž
ï¼ˆhow teams reinforce each other; strongest and weakest handoff pointsï¼‰

## å››ã€ç³»çµ±ç“¶é ¸è­˜åˆ¥
ï¼ˆbiggest performance bottleneck in the entire Federationï¼‰

## äº”ã€é€²åŒ–å»ºè­°ï¼ˆéœ€ HITL ç¢ºèªï¼‰
ï¼ˆall upgrade_needed: true items with problem description, upgrade direction, expected impact, difficulty levelï¼‰

## å…­ã€ä¸‹æœˆé‡é»žè§€å¯ŸæŒ‡æ¨™
ï¼ˆ3-5 specific quality metrics to track next evaluationï¼‰
```

### Step 7 â€” Save Report + Email HITL (agent: nebula, action: send-nebula-email)
Saves full report as `docs/meta-harness/evaluation-$today|date.md`

Subject: `ðŸ§  Meta Harness æœˆåº¦è©•ä¼°å ±å‘Š â€” $today|dateï¼ˆéœ€æ‚¨å¯©é–±ï¼‰`

Email includes:
- Three-team score summary table
- Full "Evolution Suggestions" section
- HITL action checklist:
  - âœ… Approve upgrade â†’ agent executes prompt optimization
  - âŒ Defer upgrade â†’ continue monitoring for one month
  - ðŸ”„ Need discussion â†’ reply in Nebula

Recipient: glen200392@gmail.com

---

## HITL Upgrade Threshold

| Score | Action |
|-------|--------|
| >= 85 | No action needed, continue monitoring |
| 70-84 | Flag for review, suggest minor prompt tuning |
| < 70  | `upgrade_needed: true` â€” HITL approval required |

---

## Portability Notes

| Environment | Compatibility | Notes |
|-------------|--------------|-------|
| Nebula (native) | Full | All steps run natively, HITL via email |
| LangGraph | High | Steps 3-5 as parallel evaluation nodes; Step 6 as aggregator |
| AutoGen v0.4 | High | Each team review as separate AssistantAgent; Orchestrator for Step 6 |
| CrewAI | Medium | 3 Critic Agents + 1 Synthesizer Agent |
| GitHub Actions | Medium | Steps 1-2 as HTTP actions; Steps 3-6 require LLM API integration |

**Dependencies:** Web search API, LLM API (GPT-4 class), file system write access, email delivery  
**Idempotency:** Step 7 uses date-stamped filename â€” safe to retry  
**HITL checkpoint:** Email approval required before any prompt modifications are applied  
**Evolution Engine:** Approved upgrades trigger Nebula agent prompt updates via manage_agents API